\input{src/header}											% bindet Header ein (WICHTIG)
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{fancyvrb}

\newcommand{\dozent}{Prof. Dr. Margarita Esponda}					% <-- Names des Dozenten eintragen
\newcommand{\tutor}{Lilli Walter}						% <-- Name eurer Tutoriun eintragen
\newcommand{\tutoriumNo}{6}				% <-- Nummer im KVV nachschauen
\newcommand{\projectNo}{7}									% <-- Nummer des Übungszettels
\newcommand{\veranstaltung}{Nichtsequentielle Programmierung}	% <-- Name der Lehrveranstaltung eintragen
\newcommand{\semester}{SoeSe 2017}						% <-- z.B. SoSo 17, WiSe 17/18
\newcommand{\studenten}{Boyan Hristov, Sergelen Gongor}			% <-- Hier eure Namen eintragen
% /////////////////////// BEGIN DOKUMENT /////////////////////////


\begin{document}
\input{src/titlepage}										% erstellt die Titelseite


Link zum Git Repository: \url{https://github.com/BoyanH/FU-Berlin-ALP4/tree/master/Solutions/Homework\projectNo}

% /////////////////////// Aufgabe 1 /////////////////////////

\section*{1. Aufgabe}

\begin{enumerate}
    
\item[a)]
Um diese Aufgabe richtig zu beantworten, muss man Annahme über welche Threads zu erst bei dem Scheduling-Algorithmus ankommt, obwohl die alle gleich gestartet werden. Das liegt daran, dass bei nicht prämptive Algorithmen ein Thread nie unterbrochen wird, bevor dieser zu Ende ausgeführt wurde.

\begin{enumerate}

\item[1. ] nicht-präemptive FCFS \\ \\
Hier machen wir die Annahme, dass der Thread mit 100 Minuten Ausführungszeit erster ankommt. So unterscheiden sich auch die erste 2 Teilaufgaben \\ \\
Gesammte Ausführungszeit = $100 + 100 \times 1 = 200$ \\ \\
Durchschnittliche Ausführungszeit = $ \frac{200}{101} \approx $ 1,98 Minuten \\ \\
Gesammte Wartezeit = $0 + 99 \times 100 + \sum_{i=0}^{99} i = 990 + \frac{99(99+1)}{2} = 990 + \frac{990}{2}$ = 1485\\ \\
Durchschnittliche Wartezeit = $\frac{1485}{101} \approx $ 14,7 Minuten \\ \\
Damit durchschnittliche Verarbeitungszeit $\approx $ 16,68 Minuten \\

\item[2. ] nicht-präemptive SJF \\ \\
Gesammte Ausführungszeit = $100 \times 1 + 100 = 200$ \\ \\
Durchschnittliche Ausführungszeit = $ \frac{200}{101} \approx $ 1,98 Minuten \\ \\
Gesammte Wartezeit = $(\sum_{i=0}^{99} i) + 100 = \frac{990}{2} + 100 =  $ 595 Minuten \\ \\
Durchschnittliche Wartezeit = $\frac{595}{101} \approx $ 5,89Minuten \\ \\
Damit durchschnittliche Verarbeitungszeit = $\frac{199,5 + 200}{101} \approx $ 9.82 Minuten \\

Unter der Annahme, dass 1. Thread mit 100 Minuten Ausführungszeit als 1. gescheduled wird bekommt man das Ergebniss von FCFS. Wir gehen aber davon aus, dass der Scheduling-Algorithmus schon alle Threads kennt.

\item[3. ] präemptive Shortest Remaining Time First. Quantum = 1 Minute \\
Da hier alle Threads gleichzeitig gestartet werden, gehen wir auch davon aus, dass diese in der selben Reihenfolge zu dem Scheduler ankommen. Da alle gleich gestartet werden un keine Threads mit kürzerer Ausführungszeit inzwischen kommen, ist die Ausführung analog zu diese von nicht-präemptive SJF. \\

Man kann hier die Annahme machen, dass 1. Thread mit Ausführungszeit von 100 Minuten als erster gescheduled wird und dann unterbrochen wird, dann kommt man bei dem Ergebniss von RR. Wie vorher, ist unsere Annahme, dass der Scheduler schon alle Threads kennt. \\

Durchschnittliche Wartezeit = $\frac{5051}{101} \approx $ 50 Minuten \\ \\
Durchschnittliche Verarbeitungszeit $\approx$ 3,96 Minuten \\ 

\item[4. ] RR-Scheduling. Quantum = 1 Minute \\
Bei Quantum gleich eine Minute werden alle Threads mit kleine Anforderungen gleich auf der ersten Runde ausgeführt und am Ende bleibt nur das eine Thread noch laufen. Um die Berechnung interessanter zu machen gehen wir davon aus, dass der Thread mit 100 Minuten Ausführungszeit als erster gestartet wurde.\\ \\
%
Gesammte Ausführungszeit = Ausführungszeit für 1. Thread + Ausführungszeit für restliche 100 Threads + Restausführungszeit für 1. Thread = \\
= $1 + (100 \times 1) + 99 = 200 $ \\ \\
Durchschnittliche Ausführungszeit = $\frac{200}{101} \approx $ 1,98 Minuten \\ \\
Gesammte Wartezeit = Initiale Wartezeit für 1. Thread (0) + Wartezeiten für einzelne Threads mit Ausführungszeit 1 + Wartezeit für 1. Thread = \\
= $ 0 + (\sum_{i=1}^{100} i) + 100 =  \frac{10100}{2} + 100 =  $ 5 051 Minuten \\ \\
Durchschnittliche Wartezeit = $\frac{5051}{101} \approx $ 50 Minuten \\ \\
Durchschnittliche Verarbeitungszeit = $\frac{200,5 + 200}{101} \approx $ 3,965 Minuten 


\end{enumerate}

\item[b)]
Nicht-prämptive FCFS ist ein sehr simpler Algorithmus mit geringsten Overhead. Der ist gut für Scheduling von unabhängige, gleich große Aufgaben, die erst dann fertig sind, wenn alle fertig sind. Z.B. bei Verarbeitung und Analyse von Daten an einem Server.

Nicht-präemptive SJF ist besser für Scheduling von unterschiedlich-aufwändige Aufgaben, wo wir relativ sicher sind, dass keine neue Aufgaben inzwischen kommen. Der Algorithmus ist wieder aufwändbar für Bearbeitung von schon am Anfang bekannte Jobs. Diser Algorithmus funktioniert aber wesentlich besser für Jobs mit unterschiedliche Ausführungszeit.

Präemptive Shortest Remaining Time First ist schon deutlich besser für simple Betriebssysteme. Hier können Jobs mit unterschiedliche Aufforderungen gut behandelt werden, neu gekommene Threads mit kurze Ausführungszeiten müssen nicht lange warten. 

Mit Round-Robin kann man aber deutlich besser Scheduler für Threads mit unbekannte Ausführungszeiten bauen. Das liegt daran, dass jeden Thread eien feste Zeitfenster kriegt, in dem dieser fertig sein soll, sonst wartet er auf die nächste Runde. Der Algorithmus eignet sich gut für Systemen, wo Ausführungszeit von einzelne Threads schwer zu schätzen ist.

\end{enumerate}

\section*{2. Aufgabe}

\begin{enumerate}

\item[a)]
FCFS - Es könnte sein, dass einige Threads lange auf den aufwändigen Threads vor denen warten, die werden aber alle irgendwann ausgeführt, da der Algorithmus mit einer Schlange funktioniert.

\item[b)]
SJF - Hier können aufwändigere Threads sehr leicht verhungern, in dem immer wieder neue Threads kommen mit sehr geringe Ausführungszeit.

\item[c)]
RR - hier könnte es wieder sein, dass einige Threads mit längeren Ausführungszeiten mehrmals gestartet / weiter ausgeführt werden bevor diese fertig werden, Threads werden aber nicht verhungern.

\item[d)]
O(1) früheres Linux-Scheduling - Threads mit geringere Priorität haben nur halb so große Quantums, es könnte wieder sein dass einige deutlich länger verarbeitet werden, Threads verhungern aber wieder nicht.

\item[e)]
Hybrid Lottery Scheduling - da alle Prozesse eine Mindestanzahl von Losen haben, verhungern keine Prozesse / Threads.

\item[f)]
Completely Fair Scheduling - die Frage kann mit Argumente aus der Vorlesung leider nicht beantwortet werden. Der Fair Scheduler benutzt aber die Zeit, in dem ein Prozess zu der Scheduler gekommen ist, als auch die letzte Ausführungszeit um die Prioritäten von ältere Prozessen zu erhöhen, vermeidet so erfolgreich das Verhungern von Prozessen.

Quelle $\rightarrow$ \url{https://stackoverflow.com/questions/39725102}

\end{enumerate}

\section*{3. Aufgabe}

Die Bilder kann man in GitHub besser anschauen

\begin{enumerate}

\item[a)] RMS \\
\includegraphics[width=\textwidth]{./exercise3/RMS.jpg} \clearpage
\item[b)] DMS \\
\includegraphics[width=\textwidth]{./exercise3/DMS.jpg} \clearpage
\item[c)] EDF \\
\includegraphics[width=\textwidth]{./exercise3/EDF.jpg} \clearpage
\item[d)] LLF \\
\includegraphics[width=\textwidth]{./exercise3/LLF.jpg} 

\end{enumerate}

\section*{4. Aufgabe}
Ja, das System ist realisierbar. In einer Sekunde gibt es 1000 Millisekunden, deswegen müssen wir ein Bild je $\frac{1000}{25} = 40$ Millisekunden fertig kriegen. Wir könne mit dem LLF Algorithmus das Problem leicht lösen. Wenn man die Zeit in 5-Millisekunden-Abschnitte zerteilt, wird in der ersten Millisekunde die Sprachverbindung bearbeitet und in den restlichen 4 die Bildbearbeitung. So schafft man die ganze Bildbearbeitung in 5 solche Abschnitte (20ms Bearbeitung) und verpasst dadurch keine Sprachverbindung. Das ganze ist aber nur unter der Annahme möglich, dass LLF kleines Overhead hat, was leider nicht der Fall ist. Da es aber um ein weiches Echtzeitsystem geht, können wir es immer realisieren, in dem die Qualität vermindert wird.

\clearpage

\section*{5. Aufgabe}

Die Aufgabe wurde unter der Annahme gelöst, dass das System eine weiche Echtzeitsystem ist. Sonst könnte man leicht eine Fehler in dem Task Klasse werfen und diese in dem Scheduler abfangen und terminieren.

\begin{lstlisting}[style=java]
package fu.alp4;

public class Main {

    public static void main(String[] args) {

        Task[] tasksForSimulation = {
                new Task(0,2,7,7),
                new Task(0,3,9,9),
                new Task(0,1,11,11),
                new Task(0,1,6,6)
        };
        RealTimeScheduler scheduler = new RealTimeScheduler(tasksForSimulation, 22);
        scheduler.simulateRMS();
    }
}

\end{lstlisting}


\begin{lstlisting}[style=java]
package fu.alp4;

import java.util.Arrays;

public class RealTimeScheduler {

    private Task[] managedTasks;
    private int simulationTime;
    private Task latestExecuted;

    public RealTimeScheduler(Task[] tasks, int st) {
        this.managedTasks = tasks;
        this.simulationTime = st;
    }

    public void simulateRMS() {
        this.setPrioritiesRMS();

        System.out.println("\nSimulation starting!\n\n");

        while(this.simulationTime > 0) {

            boolean taskAlreadyExecutedInCurrentLoop = false;

            // managed tasks already sorted by priority
            for(Task task : this.managedTasks) {
                if (task.getReady() && !taskAlreadyExecutedInCurrentLoop) {

                    if (this.latestExecuted == null) {
                        this.latestExecuted = task;
                    } else if (this.latestExecuted != task) {
                        System.out.printf("Task with #id %s was interrupted in favour of task with #id %s\n\n",
                                this.latestExecuted.getId(), task.getId());
                        this.latestExecuted = task;
                    }

                    task.execute();
                    taskAlreadyExecutedInCurrentLoop = true;

                } else {
                    task.keepBlocked();
                }
            }

            this.simulationTime--;
        }

    }

    private void setPrioritiesRMS() {
        // Sort managedTask by period
        Arrays.sort(this.managedTasks, (a, b) -> a.getPeriod() < b.getPeriod() ? -1 :
            a.getPeriod() == b.getPeriod() ? 0 : 1);

        // and assign priorities equal to reverse sorting number (e.g. the task with lowest period will be first and
        // will receive highes priority equal to the number of managed tasks)
        for (int i = 0; i < this.managedTasks.length; i++) {
            Task currentTask = this.managedTasks[i];
            currentTask.setPriority(this.managedTasks.length - i);
            System.out.printf("Task id: %s; Period: %s; Priority: %s\n",
                    currentTask.getId(), currentTask.getPeriod(), currentTask.getPriority());
        }
    }

}

\end{lstlisting}

\begin{lstlisting}[style=java]
package fu.alp4;

public class Task {

    static int idCounter;

    private int release;
    private int execution;
    private int executionLeft;
    private int timePassed;
    private int deadline;
    private int deadlineAfter;
    private int period;

    private int priority;
    private int id;

    /**
     * A Task manages itself in terms of setting its own deadlineAfter and executionLeft.
     * The idea is to let the scheduler-class only implement the scheduler logic, as if it was
     * gathering the data from the Process-Control-Block
     */

    public Task(int r, int e, int d, int p) {
        this.release = r;
        this.execution = e;
        this.executionLeft = release == 0 ? e : 0;
        this.deadline = d;
        this.deadlineAfter = d;
        this.period = p;
        this.timePassed = 0;
        this.setPriority(idCounter); // initially set priority = highest possible, will be changed later on

        /**
         * Priority can be between 1/n and n/n for n tasks in the scheduler.
         */

        this.id = ++idCounter;
    }


    public int getPeriod() {
        return period;
    }

    public boolean getReady() {
        return this.executionLeft > 0;
    }

    public int getPriority() {
        return priority;
    }

    public int getId() {
        return this.id;
    }

    public void setPriority(int priority) {
        this.priority = priority;
    }

    public void execute() {
        this.executionLeft--;
        this.passTime();
        System.out.printf("Task with id %s and priority %s executed. \n\t Execution left: %s; Deadline after: %s ;Time passed: %s\n\n",
                this.id, this.getPriority(), this.executionLeft, this.deadlineAfter, this.timePassed);
    }

    public void keepBlocked() {
        this.passTime();
    }

    private void passTime() {
        this.timePassed++;
        this.deadlineAfter--;

        if (this.executionLeft > 0 && this.deadlineAfter == 0) {
            System.out.printf("Task with id %s and priority %s missed it's deadline!\n\n", this.id, this.getPriority());
        } else if (this.timePassed % this.period == 0 || this.timePassed == this.release) {
            this.deadlineAfter = this.deadline;
            this.executionLeft = this.execution;
        }
    }
}

\end{lstlisting}

\section*{6. Aufgabe}

\begin{enumerate}

\item[e)]
Yeah, I read the docummentation, I promise! :)

\item[f)]
Auf Zeile 40 kriegen wir ein byte[] von dem MD5 Hash als einen Byte Array. Das wollen wir aber gerne als String[] haben, damit wir es leichter speichern können (als Klartext) oder mit andere Hashes vergleichen können. Da aber der byte[] ein Array von signed Bytes ist (also negative auch) und Java hardkodierte hexadecimal Nummer immer als positiv annimmt können wir so festdefinieren, dass wir da positive 16bit Nummer haben (mit array[i] \& 0xFF). Da aber in MD5 definiert ist, dass jedes byte 2 Positionen nimmt (2 Digits in Hexadezimalsystem) verodern wir das Ergebniss mit 0x100, oder (0001 0000 0000$)_2$ damit wir für 0x01 entsprechend "01" bekommen und nicht "1". Alle 2-Digit Hexadezimalzahlen, die von je ein Byte konvertiert werden, werden zu dem Endergebniss appended, was am Ende zurückgegeben wird.

\item[g)]

\begin{lstlisting}[style=java]
package hashCracker;


import fx.ResultPool;

public class SimpleCracker implements HashCracker {

    ResultPool resPool;
    boolean stopped;

    @Override
    public void start(String[] wordList, String[] hashList, ResultPool resPool) {

        this.stopped = false;

        for (int i = 0; i < wordList.length; i++) {
            for (int j = i; j < wordList.length; j++) {
                String wordA = wordList[i];
                String wordB = wordList[j];
                String variantA = wordA + wordB;
                String variantB = wordB + wordA;

                for (int k = 0; k < hashList.length; k++) {
                    if (MD5(variantA).equals(hashList[k])) {
                        resPool.pushPassword(variantA);
                    } else if (MD5(variantB).equals(hashList[k])) {
                        resPool.pushPassword(variantB);
                    }

                    if (this.stopped) {
                        return;
                    }
                }
            }
        }
    }

    @Override
    public void stop() {
        this.stopped = true;
    }

    public static String MD5(String md5) {
        try {
            java.security.MessageDigest md = java.security.MessageDigest.getInstance("MD5");
            byte[] array = md.digest(md5.getBytes());
            StringBuffer sb = new StringBuffer();
            for (int i = 0; i < array.length; ++i) {
                sb.append(Integer.toHexString((array[i] & 0xFF) | 0x100).substring(1, 3));
            }
            return sb.toString();
        } catch (java.security.NoSuchAlgorithmException e) {
        }
        return null;
    }


}

\end{lstlisting}

\item[h)]
Wir haben die einfache Lösung genommen und versucht, diese so gut wie möglich auf 4 Prozessoren skalieren zu lassen, da wir davon ausgegangen sind, dass die meiste Laptops heutzutage genau so viele CPU Cores haben bzw. so viele simulieren durch Hyperthreading.

Dabei haben wir gesehen, dass wenn wir die Äußere Schleife durch 4 teilen und das separat rechnen lassen, die Threads die ein größeres Anfagsindex haben wenigere Werte ausrechnen (da die innere Schleife von i anfängt) und nämlich genau $\frac{n}{4}$ bei n mögliche Wörter. Da wir aber keine perfekte aufteilung finden könnten, haben wir gemeint, dass es relativ ok ist, dass der 1 Thread $\frac{n}{8}$ wenigere Elemente in der äußere Schleife ausrechnen soll und der letzten entsprechend so viel mehrere. \\ \\

\item[Code]
Nice try, klappte aber eigentlich nicht so gut.

\begin{lstlisting}[style=java]
package hashCracker;

import fx.ResultPool;

public class CrackerThread extends Thread {

    String[] wordList;
    String[] hashList;
    ResultPool resPool;
    int startIndex;
    int endIndex;
    boolean stopped;

    public CrackerThread(String[] wordList, String[] hashList, ResultPool resPool, int i) {
        this.wordList = wordList;
        this.hashList = hashList;
        this.resPool = resPool;
        this.startIndex = (int) Math.floor(i*wordList.length/4);
        this.endIndex = (int) Math.ceil(startIndex + wordList.length/4);
        this.stopped = false;

        // spaghetti part here, just wanted to try this prototype solution
        // could be fixed at some point

        if (i == 3) {
            this.startIndex -= (int) Math.ceil(wordList.length / 8);
        } else if (i != 0) {
            this.startIndex -= (int) Math.ceil(wordList.length / 8);
            this.endIndex -= (int) Math.ceil(wordList.length / 8);
        } else {
            this.endIndex -= (int) Math.ceil(wordList.length / 8);
        }

        if (this.startIndex < 0) {
            this.startIndex = 0;
        }

        if (this.endIndex > this.wordList.length) {
            this.endIndex = this.wordList.length;
        }
    }

    public void stopCalc() {
        this.stopped = true;
    }

    @Override
    public void run() {

        int count = 0;
        int gausNumber = this.endIndex - 1 - startIndex;
        String[] pairs = new String[gausNumber*(gausNumber+1)];

        for (int i = this.startIndex; i < this.endIndex; i++) {
            for (int j = i; j < wordList.length; j++) {

                String[] variants = {
                        wordList[i] + wordList[j],
                        wordList[j] + wordList[i],
                        wordList[i],
                        wordList[j]
                };

                for (String hash : hashList) {
                    for (String variant : variants) {
                        if (MD5(variant).equals(hash)) {
                            resPool.pushPassword(variant);
                        }
                    }

                    if (this.stopped) {
                        return;
                    }
                }
            }
        }

    }

    public static String MD5(String md5) {
        try {
            java.security.MessageDigest md = java.security.MessageDigest.getInstance("MD5");
            byte[] array = md.digest(md5.getBytes());
            StringBuffer sb = new StringBuffer();
            for (int i = 0; i < array.length; ++i) {
                sb.append(Integer.toHexString((array[i] & 0xFF) | 0x100).substring(1, 3));
            }
            return sb.toString();
        } catch (java.security.NoSuchAlgorithmException e) {
        }
        return null;
    }
}

\end{lstlisting}

\begin{lstlisting}[style=java]
package hashCracker;


import fx.ResultPool;

public class BetterCracker implements HashCracker {

    ResultPool resPool;
    CrackerThread[] crackerThreads;

    @Override
    public void start(String[] wordList, String[] hashList, ResultPool resPool) {

        this.crackerThreads = new CrackerThread[4];

        for (int i = 0; i < 4; i++) {
            this.crackerThreads[i] = new CrackerThread(wordList, hashList, resPool, i);
            this.crackerThreads[i].start();
        }

        for (int t = 0; t < this.crackerThreads.length; t++) {
            try {
                this.crackerThreads[t].join();
                this.stop();
            } catch (InterruptedException e) {
                e.printStackTrace();
            }
        }
    }

    @Override
    public void stop() {

        for (CrackerThread thread : this.crackerThreads) {
            thread.stopCalc();
        }
    }
}

\end{lstlisting}

\end{enumerate}

% /////////////////////// END DOKUMENT /////////////////////////
\end{document}